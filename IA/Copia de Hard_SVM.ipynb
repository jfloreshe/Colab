{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia de Hard_SVM.ipynb","provenance":[{"file_id":"17JtMp8hzBmX4Wq8BLQjlQ33xh38DqyKi","timestamp":1650636246065}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import axes3d\n","import pandas as pd\n","import cvxopt\n","import math\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix"],"metadata":{"id":"Jq8Pon88bpRr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Multiplicadores de Lagrange \n","$\\frac{\\partial f(x)}{ \\partial x} = λ \\frac{\\partial g(  x)}{ \\partial x}$\n","\n","Hallar los valores de $λ_i$ para cada elemento de entrenamiento $X_i$. \n","\n","El código ***GetLambda***  debe retornar un vector al cual denominaremos lambda, de modo que\n","  $lambda[i]$ será $0$, si el elemento $X[i]$ no tiene intercesión con ninguna de las rectas\n","  $XW^t + b >=1$ o $XW^t + b >=0$\n","\n","Nota: X es una matriz, de modo que $X_i$ será un vector de dimensión $K$ que representa el i-esimo objeto o punto $k$ dimensional y $X_ij$ \n","\n","\n","\n","- **Nota: Puede buscar en internet la forma de como hallar lambda.**"],"metadata":{"id":"_-o70Lb1qRVv"}},{"cell_type":"code","source":["def gaussian_kernel(x, y, sigma=5.0):\n","  return np.exp(-(np.linalg.norm(x-y))**2 / (2 * (sigma ** 2)))\n","\n","def generate_k(X):\n","  n_samples = X.shape[0]\n","  K = np.zeros((n_samples, n_samples))\n","  for i in range(n_samples):\n","    for j in range(n_samples):\n","      #K[i,j] = gaussian_kernel(np.array(X.iloc[i].to_list()), np.array(X.iloc[j].to_list()))\n","      K[i, j] = gaussian_kernel(X[i], X[j])\n","  return K\n","\n","def GetLambda(X,Y,C=0.1):   \n","  # write your code here \n","  K = generate_k(X)\n","  n_samples = X.shape[0]\n","  \n","  np.outer(Y, Y)\n","  Y = Y.astype(np.double)\n","  P = cvxopt.matrix(np.outer(Y,Y) * K)\n","  q = cvxopt.matrix(np.ones(n_samples) * -1)\n","  A = cvxopt.matrix(Y, (1,n_samples))\n","  b = cvxopt.matrix(0.0)\n","\n","  if C is None:\n","    G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n","    h = cvxopt.matrix(np.zeros(n_samples))\n","  else:\n","    tmp1 = np.diag(np.ones(n_samples) * -1)\n","    tmp2 = np.identity(n_samples)\n","    G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n","    tmp1 = np.zeros(n_samples)\n","    tmp2 = np.ones(n_samples) * C\n","    h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n","\n","  print(len(A))\n","  solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n","  return np.ravel(solution['x'])"],"metadata":{"id":"LZfgE-fAqRCl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2 Cálculo de los pesos W\n","$W_j = \\sum_{i=0}^n \\lambda_iy_ix_{ij}$  \n","\n","Donde: λ_i es el i-esimo multiplicador de lagrange, W_j es el W-esimo peso y x_{ij} es el valor de la característica $j$ del objeto de entrenamiento $i-esimo$ y $y_i$ es la salida esperada (1 o - 1) del objeto $i$.\n","\n","Recuerde la sumatoria solo recorre todos los elementos para los cuales el valor del multiplicador de lagrange $λ_i$ es diferente de 0."],"metadata":{"id":"Lbvs2lvNlmNa"}},{"cell_type":"code","source":["def Get_W(X,Y, lambda):\n","# write your code here"],"metadata":{"id":"xJwm8DaClJ-f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Cálculo de b\n","\n","XW^t + b = 0 \n","\n","$b = - \\frac{1}{n}∑_{i=0}^n X_iW^t$\n","\n","Donde $X_i$ es un vector $k$ dimensional y representa el objeto $i-esimo$ de entrenamiento y $k$ el número de características del objeto."],"metadata":{"id":"wctPuU-jnU0Q"}},{"cell_type":"code","source":["def Get_b(X,W):\n","  # write your code here"],"metadata":{"id":"IujB29jtnUl7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Etapa de Testing\n","\n","Para esta estapa solo se debe calcular\n","\n","$f(X_j) = X_jW^t + b$\n","\n","Pero dado que ya hemos calculado el valor de los parámetros $W$ y $b$, entonces remplazando tenemos\n","\n","$f(X_j) = \\sum_{i=0}^n \\lambda_iy_i<X_{i},X_{j}> + b$\n","\n","Donde: $X_i$ i-esimo  es el vector de entrenamiento y $X_j$ es el nuevo vector que pasa por el modelo para su predicciòn predecir la clase (1 o -1).\n","\n","Finalmente para saber a que clase pertenece el nuevo vector $X_j$ vasta con verificar el signo de f(X_j). \n","\n","  - **If $f(X_j) >=0$ then $Y_j$ = 1 else $Y_j = -1$**"],"metadata":{"id":"k7L3GAtNoUo7"}},{"cell_type":"code","source":["def Test(X,W,b):\n","  # write your code here"],"metadata":{"id":"froBqp3Mp9C5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Base de Datos para Las pruebas:\n","[Download](https://gist.github.com/netj/8836201)\n","\n","En esta base de datos existen 3 clases, solo utilize dos clases para hacer las pruebas.\n","\n","- Separe el dataset en 70% para entrenar y 30% para hacer las pruebas\n","\n","- Añada un valor 1 para la primera clase  y  -1 para la segunda clase.\n","\n","- En la etapa de test, encuentre el número de elementos correctamente clasificados y el número de elementos incorrectamente clasificados para cada clase.\n","\n","- Cree una matriz de confusión el cual nos mostrará la eficiencia del método."],"metadata":{"id":"LslGSJAprlPm"}},{"cell_type":"code","source":[""],"metadata":{"id":"LyqDjy_urgh1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"5RIbIG16xxB7"},"execution_count":null,"outputs":[]}]}