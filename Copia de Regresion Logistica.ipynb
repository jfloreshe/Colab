{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia de Regresion Logistica.ipynb","provenance":[{"file_id":"121tp6uKQO3B7xrd0dr-xlxz-jCvwFjCM","timestamp":1650459073690}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Práctica de Regresión Lógistica: Cancer de mama\n","\n","***Por favor, trabaje en una copia de este  colab***"],"metadata":{"id":"ZvH40s0XZ8he"}},{"cell_type":"markdown","source":["**Base de datos**: [Click](https://drive.google.com/file/d/1YccFuyedpJ7-rek4iR3MSviB0jv80uqZ/view?usp=sharing)\n","\n","El conjunto de datos contiene casos de un estudio realizado entre 1958 y 1970 en el Hospital Billings de la Universidad de Chicago sobre la supervivencia de pacientes que se habían sometido a cirugía por cáncer de mama.\n","\n","La base de datos está formada por 306 objetos, cada objeto tiene 3 características (Edad del paciente al momento de la operación, Años de operación y Número de ganglios axilares positivos detectados) y un predictor (variable a predecir estado de supervivencia, 1 si el paciente vivió, 2 si el paciente murío)\n","\n","*Se pide predecir, en base a las características de un paciente,  si un paciente sobrevivirá o no*"],"metadata":{"id":"BiMdtNbVlMTd"}},{"cell_type":"code","source":["import numpy as np \n","import pandas as pd\n","from sklearn.preprocessing import normalize\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","drive.mount (\"/content/gdrive\")\n","data = pd.read_csv('gdrive/My Drive/dataset.data')\n","X = pd.DataFrame(data, columns = ['edad','anhos','ganglios'])\n","Y = pd.DataFrame(data, columns = ['pred'])\n","X = normalize(X)\n","Y = normalize(Y)\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)"],"metadata":{"id":"UDEHxYo2iDYq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650460493995,"user_tz":300,"elapsed":2399,"user":{"displayName":"JEFFERSON MIGUEL FLORES HERRERA","userId":"18094869842707251178"}},"outputId":"ad50e8f3-9e6d-419f-c2ae-aabe34aa9783"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","     edad  anhos  ganglios\n","0      30     64         1\n","1      30     62         3\n","2      30     65         0\n","3      31     59         2\n","4      31     65         4\n","..    ...    ...       ...\n","301    75     62         1\n","302    76     67         0\n","303    77     65         3\n","304    78     65         1\n","305    83     58         2\n","\n","[306 rows x 3 columns]      pred\n","0       1\n","1       1\n","2       1\n","3       1\n","4       1\n","..    ...\n","301     1\n","302     1\n","303     1\n","304     2\n","305     2\n","\n","[306 rows x 1 columns]\n"]}]},{"cell_type":"markdown","source":["\n","\n","**Hipótesis**:\n","\n","- Ecuación de la recta o Hiperplano\n","\\begin{equation}\n","h(x_i) = w_0 + w_1x_i^1 +  w_2x_i^2 ... w_kx_i^k\n","\\end{equation} \\\\\n","\n","- Ecuación de la función sigmoidea (clasificador binario)\n","\\begin{equation}\n","s(x_i) = \\frac{1}{1 + e^{-h(x)}} \n","\\end{equation}\n","\n","\n","\n","\n"],"metadata":{"id":"eF1-EUpeaGvZ"}},{"cell_type":"code","source":["def Hiperplano(x,w):\n","  # write your code here\n","  return np.dot(x, np.transpose(w))\n","def S(x,w):\n","  result = 1/(1+np.exp(Hiperplano(x,w)))\n","  return round(result)\n","  "],"metadata":{"id":"IccO1C-1b6gH","executionInfo":{"status":"ok","timestamp":1650461730113,"user_tz":300,"elapsed":309,"user":{"displayName":"JEFFERSON MIGUEL FLORES HERRERA","userId":"18094869842707251178"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["- **Loss Function** (Cross-Entropy)\n","\n","\\begin{equation}\n","L = -\\frac{1}{n}\\sum_{i=0}^n(y_ilog(s(x_i)) + (1-y_i)log(1-s(x_i)))  \n","\\end{equation} \\\\\n"],"metadata":{"id":"TsEclK8ZcDAv"}},{"cell_type":"code","source":["def Loss_function(x,y,w):\n","  # write your code here \n","  sum = 0\n","  for i in range(len(x)): \n","    Sx_i = S(x[i],w)\n","    if Sx_i == 0:\n","      Sx_i = 0.000000001\n","    elif Sx_i == 1:\n","      Sx_i = 0.999999999\n","    sum += y[i]*np.log(Sx_i) + (1-y[i])*np.log(1-Sx_i)\n","  sum = sum / len(x)\n","  return sum"],"metadata":{"id":"KDeZtXSecvnb","executionInfo":{"status":"ok","timestamp":1650461726423,"user_tz":300,"elapsed":289,"user":{"displayName":"JEFFERSON MIGUEL FLORES HERRERA","userId":"18094869842707251178"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["- **Derivatives**\n","\n","\\begin{equation}\n","\\frac{\\partial L}{\\partial w_j} = \\frac{1}{n}\\sum_{i=0}^n(y_i - s(x_i))(-x_i^j)\n","\\end{equation} \\\\\n","\n","Nota:  $x_i^j$ se refiere a la característica $j-esima$ del objeto $i-esimo$ de entrenamiento\n"],"metadata":{"id":"Y5e7Tbc_c7Y8"}},{"cell_type":"code","source":["def Derivatives(x,y,w):\n","  # write your code here\n","  dw = np.zeros(len(w))\n","\n","  for i in range(len(x)):\n","    for j in range(len(x[i])):\n","      dw[j] += (y[i] - h(x[i],w,b))*(-x[i][j])\n","  \n","  dw = dw/len(x)\n","    \n","  return db, dw"],"metadata":{"id":"g4cD0fHuc6_I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Change parameters \n","\n","\\begin{equation}\n"," w_j = w_i - \\alpha\\frac{\\partial L}{\\partial w_j} \n","\\end{equation}"],"metadata":{"id":"h_YvV9kAfQFL"}},{"cell_type":"code","source":["def change_parameters(w, derivatives, alpha):\n","  # write your code here"],"metadata":{"id":"sN6Mj8G_fnPA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **Training** \n","\n","Seleccione $70\\%$ de los datos del dataset para entrenamiento y el resto para testing. Recuerde, los datos deben ser seleccionados de manera aleatoría.\n","\n","\n"],"metadata":{"id":"LWEJPUGWfykV"}},{"cell_type":"code","source":["def training(x,y, epochs):\n","  for i in range(epochs):\n","    L =  Loss_function(x,y)\n","    dw = Derivatives(x,y,w)\n","    w =  change_parameters(w, dw, alpha)"],"metadata":{"id":"-4iDI_owgkIV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- **Testing**\n","\n","Utilize el $30\\%$ de los datos restantes para el proceso de testing. "],"metadata":{"id":"17O_Nrq5g3Ma"}},{"cell_type":"code","source":["def Testing(x_test, y_test):\n","   n = len(y_test)\n","   y_pred = []\n","   for i in range(n):\n","     y_pred.append(S(x_test,w))\n","   print(\"Número de datos correctos\", sum(y_pred == y))\n"],"metadata":{"id":"_Y7UDBtBg2cs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Desarrolle las siguientes actividades \n","\n","- Implemente funciones para graficar la función de pérdida. \n","- Implemente la función para mostrar las funciones de error de training vs testing \n","-¿Qué porcentaje de aciertos tiene el método?\n","-¿Qué porcentaje de fallas tiene el método?\n"," \n","\n"],"metadata":{"id":"Th-ybXehkbAa"}},{"cell_type":"markdown","source":["Un exelente libro: [click](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)"],"metadata":{"id":"nnIBN6QAqOmG"}}]}